{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb2a6bf",
   "metadata": {},
   "source": [
    "Author: Julia Wervers\n",
    "Student Number: 13168665\n",
    "\n",
    "This is the main script for the final project of the data processing course. The objective of the project is to find how representative lists of keywords extracted from summaries of books compared to keywords extracted from the book themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2dce7841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Load a large nlp pipeline with vectors\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "adc0523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Functions\n",
    "\n",
    "#Function to get wordlist of a textfile\n",
    "def get_book_wordlist(textfile):\n",
    "    #Get text \n",
    "    f = open(f'data/{textfile}', \"r\", encoding=\"utf8\")\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    doc = nlp(text)\n",
    "    #Iterate through the tokens and get the lowercase lemma of each token if the token is not a stopword and is not punctuation\n",
    "    lemmas = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "    #clean up the extracted text\n",
    "    processed_text = \" \".join(lemmas).strip()\n",
    "    #Split the text up using space into a list of words\n",
    "    wordlist = processed_text.split()\n",
    "                      \n",
    "    return(wordlist)\n",
    "\n",
    "#Function to get the term frequency of a list of words\n",
    "def get_term_frequency(wordlist):\n",
    "    word_frequency = Counter(wordlist)\n",
    "    total_words = len(word_frequency)\n",
    "    term_frequency = {term: count / total_words for term, count in word_frequency.items()}\n",
    "    return(term_frequency)\n",
    "\n",
    "def get_tfidf(document_list):\n",
    "    total_words = []\n",
    "    term_frequency_list = []\n",
    "    for book in books:\n",
    "        wordlist = get_book_wordlist(book)\n",
    "        total_words.append(wordlist)\n",
    "        term_frequency = get_term_frequency(wordlist)\n",
    "        term_frequency_list.append(term_frequency)\n",
    "\n",
    "    #Create a list of all unique words in the texts\n",
    "    all_words = set([word for sublist in total_words for word in sublist])\n",
    "\n",
    "    #Get the document frequency for each word\n",
    "    document_frequency = {word: sum(1 for sublist in total_words if word in sublist) for word in all_words}\n",
    "\n",
    "    #Calculate Inverse Document Frequency for each word\n",
    "    amount_documents = len(books)\n",
    "    inverse_document_frequency = {word: math.log(amount_documents / document_frequency[word]) for word in document_frequency}\n",
    "\n",
    "    #Get the 100 words with the highest tfidf score per book\n",
    "    tfidf_list = []\n",
    "    for book in term_frequency_list:\n",
    "        #Calculate the tfidf per word\n",
    "        tfidf = {word: term_frequency * inverse_document_frequency[word] for word, term_frequency in book.items()}\n",
    "        #Sort the dictionary \n",
    "        tfidf = dict(sorted(tfidf.items(), key=lambda item: item[1], reverse=True))\n",
    "        #Turn the words to a list and select the 100 words with the highest tfidf scores\n",
    "        tfidf_list.append(list(tfidf.keys())[:100])\n",
    "    return(tfidf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b927bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['clerval', 'endeavour', 'mountain', 'justine', 'felix', 'geneva', 'elizabeth', 'bestow', 'murderer', 'frankenstein', 'wretch', 'william', 'safie', 'fear', 'surround', 'depart', 'revenge', 'cottager', 'misery', 'overcome', 'm.', 'destruction', 'being', 'beloved', 'cottage', 'creator', 'alas', 'task', 'voyage', 'progress', 'dæmon', 'horror', 'acquaint', 'departure', 'thy', 'countenance', 'destroy', 'behold', 'ingolstadt', 'quit', 'hovel', 'visit', 'perceive', 'wood', 'agitation', 'sledge', 'fatigue', 'torment', 'amiable', 'wretchedness', 'benevolent', 'tranquillity', 'protector', 'condemn', 'disposition', 'frightful', 'exertion', 'contemplate', 'summit', 'magistrate', 'abhor', 'kirwin', 'gentle', 'pursue', 'allow', 'fiend', 'misfortune', 'monster', 'undertaking', 'apply', 'mont', 'labour', 'peace', 'enemy', 'agony', 'mankind', 'sustain', 'sympathise', 'permit', 'accordingly', 'compassion', 'enjoyment', 'specie', 'trial', 'reflection', 'crime', 'native', 'enterprise', 'region', 'gentleness', 'turk', 'ancient', 'ardently', 'accent', 'animate', 'residence', 'switzerland', 'guilt', 'prey', 'evil'], ['gatsby', 'wilson', 'tom', 'daisy', 'baker', 'egg', 'york', 'car', 'wolfshiem', 'garage', 'lawn', 'jordan', 'nick', 'telephone', 'buchanan', 'myrtle', 'michaelis', 'big', 'porch', 'mckee', 'cody', 'crazy', 'phone', 'forever', 'jay', 'coupé', 'gatz', 'faintly', 'carraway', 'taxi', 'chauffeur', 'sloane', 'later', 'drugstore', 'goodbye', 'unfamiliar', 'biloxi', 'sort', 'nod', 'bay', 'dollar', 'politely', 'cocktail', 'hello', 'hotel', 'dan', 'chicago', 'butler', 'abruptly', 'sharply', 'louisville', 'ash', 'eckleburg', 'block', 'whisky', 'automobile', 'golf', 'klipspringer', 'montenegro', 'meyer', 'dozen', 'island', 'coat', 'somebody', 'casually', 'movie', 'afterward', 'brick', 'obviously', 'backward', 'veranda', 'j.', 'lavender', 'lucille', 'owl', 'nineteen', 'sidewalk', 'tomorrow', 'glass', 'realize', 'mouth', 'george', 'catherine', 'policeman', 'lunch', 'haven', 'slender', 'mansion', 'incredulously', 'excitedly', 'innocently', 'saturday', 'magazine', 'pump', 't.', 'b.', 'slide', 'elevator', 'enchanted', 'towel'], ['dorian', 'harry', 'basil', 'lord', 'hallward', 'sibyl', 'gray', 'vane', 'lad', 'duchess', 'alan', 'campbell', 'narborough', 'sin', 'bye', 'studio', 'dreadful', 'painter', 'purple', 'jim', 'fascinating', 'valet', 'erskine', 'juliet', 'fascinate', 'thread', 'dominate', 'knife', 'selby', 'geoffrey', 'hideous', 'delightful', 'quarrel', 'mask', 'adrian', 'gladys', 'exquisite', 'sigh', 'artist', 'wotton', 'hansom', 'horror', 'rose', 'sort', 'canvas', 'coat', 'mere', 'worship', 'tragedy', 'club', 'polished', 'vanity', 'purity', 'kelso', 'novel', 'misshapen', 'hubbard', 'singleton', 'cigarette', 'stain', 'theatre', 'james', 'prince', 'mouth', 'london', 'subtle', 'teach', 'dainty', 'malady', 'romeo', 'stern', 'sip', 'fear', 'personality', 'horribly', 'tired', 'scarlet', 'shudder', 'tea', 'screen', 'silk', 'dine', 'coloured', 'bee', 'amazement', 'sitter', 'brandon', 'nineteenth', 'turquoise', 'purely', 'edition', 'blush', 'audience', 'finely', 'paradox', 'masterpiece', 'olive', 'hole', 'sordid', 'lack']]\n"
     ]
    }
   ],
   "source": [
    "books = [\"Frankenstein.txt\", \"Great_Gatsby.txt\", \"The_Picture_of_Dorian_Gray.txt\"]\n",
    "print(get_tfidf(books))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a436ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53153fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcab54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
